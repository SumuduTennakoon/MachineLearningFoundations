{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Foundations\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "Sumudu Tennakoon, PhD\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about Python, refeer to the following websites\n",
    "\n",
    "* Python : www.python.org\n",
    "\n",
    "To learn more about the Python packages we explore in this notebook, refeer to the following websites\n",
    "\n",
    "* NumPy : www.numpy.org\n",
    "* Matplotlib : www.matplotlib.org\n",
    "* Pandas : https://pandas.pydata.org\n",
    "* Scikit-Learn : https://scikit-learn.org/\n",
    "* Seaborn: https://seaborn.pydata.org/\n",
    "* StatsModel : https://www.statsmodels.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classfiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Parameter Serach Methods\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8tJhrdPo-xc"
   },
   "source": [
    "## 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 974
    },
    "id": "FzN3kA41ciU-",
    "outputId": "f182c996-aa2e-4d3e-ef51-02ae9827374a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29741</th>\n",
       "      <td>4923</td>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>168854</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34069</th>\n",
       "      <td>9251</td>\n",
       "      <td>72</td>\n",
       "      <td>?</td>\n",
       "      <td>235014</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15384</th>\n",
       "      <td>15390</td>\n",
       "      <td>59</td>\n",
       "      <td>Private</td>\n",
       "      <td>98361</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25848</th>\n",
       "      <td>1030</td>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>211345</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>9090</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>252424</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  age workclass  fnlwgt      education  education_num  \\\n",
       "29741        4923   31   Private  168854   Some-college             10   \n",
       "34069        9251   72         ?  235014      Assoc-voc             11   \n",
       "15384       15390   59   Private   98361   Some-college             10   \n",
       "25848        1030   23   Private  211345   Some-college             10   \n",
       "33908        9090   28   Private  252424      Assoc-voc             11   \n",
       "\n",
       "            marital_status         occupation    relationship    race  \\\n",
       "29741        Never-married              Sales   Not-in-family   White   \n",
       "34069              Widowed                  ?   Not-in-family   White   \n",
       "15384   Married-civ-spouse       Craft-repair         Husband   White   \n",
       "25848        Never-married       Adm-clerical       Own-child   White   \n",
       "33908        Never-married   Transport-moving       Own-child   Black   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "29741     Male           0.0        1504.0            40.0   United-States   \n",
       "34069   Female           0.0        2465.0            40.0   United-States   \n",
       "15384     Male           0.0           0.0            40.0   United-States   \n",
       "25848   Female           0.0           0.0            40.0       Nicaragua   \n",
       "33908     Male           0.0           0.0            40.0        Cambodia   \n",
       "\n",
       "         class  \n",
       "29741   <=50K.  \n",
       "34069   <=50K.  \n",
       "15384     >50K  \n",
       "25848   <=50K.  \n",
       "33908   <=50K.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'https://raw.githubusercontent.com/SumuduTennakoon/MLFoundations/main/Datasets/income_data.csv'\n",
    "\n",
    "# Load CSV File\n",
    "data = pd.read_csv(file_name)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessry columns and missing rows\n",
    "data.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "data.dropna(how='any', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>&lt;=50K</th>\n",
       "      <th>&lt;=50K.</th>\n",
       "      <th>&gt;50K</th>\n",
       "      <th>&gt;50K.</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12268</td>\n",
       "      <td>8124</td>\n",
       "      <td>842</td>\n",
       "      <td>526</td>\n",
       "      <td>21760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6599</td>\n",
       "      <td>4306</td>\n",
       "      <td>5109</td>\n",
       "      <td>3320</td>\n",
       "      <td>19334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>18867</td>\n",
       "      <td>12430</td>\n",
       "      <td>5951</td>\n",
       "      <td>3846</td>\n",
       "      <td>41094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class            <=50K   <=50K.   >50K   >50K.  Total\n",
       "marital_status                                       \n",
       "1                12268     8124    842     526  21760\n",
       "2                 6599     4306   5109    3320  19334\n",
       "Total            18867    12430   5951    3846  41094"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_marital_statuss_catergory(education):\n",
    "    if education in (' Married-civ-spouse',' Married-spouse-absent', ' Married-AF-spouse'):\n",
    "        return 2 #'Married'\n",
    "    elif education in (' Never-married', ' Divorced', ' Widowed',' Separated'):   \n",
    "        return 1 #'Single'\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "data['marital_status'] = data['marital_status'].apply(merge_marital_statuss_catergory)\n",
    "pd.crosstab(data['marital_status'], data['class'], margins=True, margins_name='Total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Target (y) Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31297\n",
       "1     9797\n",
       "Name: y_act, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct class labeling\n",
    "data['class'] = data['class'].replace(' >50K.', ' >50K')\n",
    "data['class'] = data['class'].replace(' <=50K.', ' <=50K')\n",
    "data['y_act'] = np.where(data['class']==' >50K',1,0)\n",
    "data['y_act'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  hours_per_week  education_num  marital_status\n",
      "0   39            40.0             13               1\n",
      "1   50            13.0             13               2\n",
      "2   38            40.0              9               1\n",
      "3   53            40.0              7               2\n",
      "4   28            40.0             13               2\n",
      "\n",
      "\n",
      "                age  hours_per_week  education_num  marital_status\n",
      "count  41094.000000    41094.000000   41094.000000    41094.000000\n",
      "mean      38.669757       40.404585      10.079355        1.470482\n",
      "std       13.748166       12.371882       2.560937        0.499134\n",
      "min       17.000000        1.000000       1.000000        1.000000\n",
      "25%       28.000000       40.000000       9.000000        1.000000\n",
      "50%       37.000000       40.000000      10.000000        1.000000\n",
      "75%       48.000000       45.000000      12.000000        2.000000\n",
      "max       90.000000       99.000000      16.000000        2.000000\n"
     ]
    }
   ],
   "source": [
    "X_variables = ['age',  'hours_per_week', 'education_num', 'marital_status']\n",
    "y_varibale = 'y_act'\n",
    "\n",
    "X = data[X_variables]\n",
    "\n",
    "print(X.head())\n",
    "print('\\n')\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  hours_per_week  education_num  marital_status\n",
      "0  0.024021       -0.032702       1.140474       -0.942609\n",
      "1  0.824138       -2.215097       1.140474        1.060886\n",
      "2 -0.048717       -0.032702      -0.421474       -0.942609\n",
      "3  1.042351       -0.032702      -1.202448        1.060886\n",
      "4 -0.776095       -0.032702       1.140474        1.060886\n",
      "\n",
      "\n",
      "                age  hours_per_week  education_num  marital_status\n",
      "count  4.109400e+04    4.109400e+04   4.109400e+04    4.109400e+04\n",
      "mean   1.735983e-16   -1.655582e-17  -2.334240e-16   -1.850102e-16\n",
      "std    1.000012e+00    1.000012e+00   1.000012e+00    1.000012e+00\n",
      "min   -1.576212e+00   -3.185050e+00  -3.545369e+00   -9.426086e-01\n",
      "25%   -7.760953e-01   -3.270234e-02  -4.214738e-01   -9.426086e-01\n",
      "50%   -1.214546e-01   -3.270234e-02  -3.098695e-02   -9.426086e-01\n",
      "75%    6.786619e-01    3.714448e-01   7.499868e-01    1.060886e+00\n",
      "max    3.733652e+00    4.736234e+00   2.311934e+00    1.060886e+00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
    "\n",
    "y = data[y_varibale]\n",
    "print(X.head())\n",
    "print('\\n')\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Correlation with Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_54b68_row0_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 52.7%, transparent 52.7%);\n",
       "}\n",
       "#T_54b68_row1_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 51.7%, transparent 51.7%);\n",
       "}\n",
       "#T_54b68_row2_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 76.2%, transparent 76.2%);\n",
       "}\n",
       "#T_54b68_row3_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_54b68\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_54b68_level0_col0\" class=\"col_heading level0 col0\" >y_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_54b68_level0_row0\" class=\"row_heading level0 row0\" >age</th>\n",
       "      <td id=\"T_54b68_row0_col0\" class=\"data row0 col0\" >0.139521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b68_level0_row1\" class=\"row_heading level0 row1\" >hours_per_week</th>\n",
       "      <td id=\"T_54b68_row1_col0\" class=\"data row1 col0\" >0.137008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b68_level0_row2\" class=\"row_heading level0 row2\" >education_num</th>\n",
       "      <td id=\"T_54b68_row2_col0\" class=\"data row2 col0\" >0.201737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54b68_level0_row3\" class=\"row_heading level0 row3\" >marital_status</th>\n",
       "      <td id=\"T_54b68_row3_col0\" class=\"data row3 col0\" >0.264779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2456eac9dc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = pd.concat([X, y], axis=1).corr()[['y_act']].drop('y_act')\n",
    "correlation.style.bar(align='mid', color=['#d65f5f', '#5fba7d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample size = 28765\n",
      "Test sample size  = 12329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(F\"Train sample size = {len(X_train)}\")\n",
    "print(F\"Test sample size  = {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_profile:\n",
      "           feature  coefficients\n",
      "0             age      0.413008\n",
      "1  hours_per_week      0.414359\n",
      "2   education_num      0.969832\n",
      "3  marital_status      1.159059\n",
      "intercept: -1.8842029313000297\n",
      "\n",
      "\n",
      "Model Parameters:\n",
      " C                       1.0\n",
      "class_weight           None\n",
      "dual                  False\n",
      "fit_intercept          True\n",
      "intercept_scaling         1\n",
      "l1_ratio               None\n",
      "max_iter                100\n",
      "multi_class            auto\n",
      "n_jobs                 None\n",
      "penalty                  l2\n",
      "random_state           None\n",
      "solver                lbfgs\n",
      "tol                  0.0001\n",
      "verbose                   0\n",
      "warm_start            False\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "features_to_model = X_variables\n",
    "\n",
    "# Create Model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance/Coefficients\n",
    "coefficients = model.coef_[0]\n",
    "intercept = model.intercept_[0]\n",
    "feature_profile = pd.DataFrame({\"feature\":features_to_model, \"coefficients\":coefficients})\n",
    "print(\"feature_profile:\\n\", feature_profile)\n",
    "print(\"intercept:\", intercept)\n",
    "print('\\n')\n",
    "print(\"Model Parameters:\\n\", pd.Series(model.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3644135  0.05197569 0.13738742 0.22635666 0.62836357]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9534</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_act  y_pred  y_pred_prob\n",
       "9670       0       0     0.094077\n",
       "9534       1       1     0.544257\n",
       "1640       1       0     0.333838\n",
       "2033       0       0     0.002941\n",
       "9560       0       0     0.392672\n",
       "9319       0       0     0.049164\n",
       "420        0       0     0.043474\n",
       "4925       1       0     0.491308\n",
       "1892       0       0     0.270104\n",
       "12128      1       0     0.140668"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_test[features_to_model])\n",
    "y_pred_prob = model.predict_proba(X_test[features_to_model])[:,1]\n",
    "print(y_pred_prob[:5])\n",
    "\n",
    "test_result = pd.DataFrame(data={'y_act':y_test.values, 'y_pred':y_pred, 'y_pred_prob':y_pred_prob})\n",
    "test_result.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " y_pred      0     1    All\n",
      "y_act                     \n",
      "0        8619   704   9323\n",
      "1        1540  1466   3006\n",
      "All     10159  2170  12329\n",
      "\n",
      "\n",
      "acuracy_lgr: 0.817990104631357\n",
      "f1_score_lgr: [0.88481675 0.56646059]\n",
      "\n",
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      9323\n",
      "           1       0.68      0.49      0.57      3006\n",
      "\n",
      "    accuracy                           0.82     12329\n",
      "   macro avg       0.76      0.71      0.73     12329\n",
      "weighted avg       0.81      0.82      0.81     12329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cfm = pd.crosstab(test_result['y_act'], test_result['y_pred'], margins=True)\n",
    "print(\"Confusion Matrix:\\n\", cfm)\n",
    "print('\\n')\n",
    "\n",
    "# Model evaluation\n",
    "# Use Scikit-Learn function (lgr = Logistic Regression)\n",
    "acuracy_lgr = metrics.accuracy_score(test_result['y_act'], test_result['y_pred']) \n",
    "print(\"acuracy_lgr:\", acuracy_lgr)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "f1_score_lgr = metrics.f1_score(test_result['y_act'], test_result['y_pred'], average=None)  #weighted accounts for label imbalance.\n",
    "print(\"f1_score_lgr:\",f1_score_lgr)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"classification_report:\\n\",classification_report(test_result['y_act'], test_result['y_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_profile:\n",
      "           feature  importance\n",
      "0             age    0.240750\n",
      "1  hours_per_week    0.185898\n",
      "2   education_num    0.247762\n",
      "3  marital_status    0.325590\n",
      "\n",
      "\n",
      "Model Parameters:\n",
      " ccp_alpha                    0.0\n",
      "class_weight                None\n",
      "criterion                   gini\n",
      "max_depth                   None\n",
      "max_features                None\n",
      "max_leaf_nodes              None\n",
      "min_impurity_decrease        0.0\n",
      "min_samples_leaf               1\n",
      "min_samples_split              2\n",
      "min_weight_fraction_leaf     0.0\n",
      "random_state                None\n",
      "splitter                    best\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "features_to_model = X_variables\n",
    "\n",
    "# Create Model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance/Coefficients\n",
    "importance = model.feature_importances_\n",
    "feature_profile = pd.DataFrame({\"feature\":features_to_model, \"importance\":importance})\n",
    "print(\"feature_profile:\\n\", feature_profile)\n",
    "print('\\n')\n",
    "print(\"Model Parameters:\\n\", pd.Series(model.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27906977 0.         0.         0.         0.54545455]\n",
      "       y_act  y_pred  y_pred_prob\n",
      "11822      0       0     0.000000\n",
      "4663       0       1     0.645161\n",
      "3596       0       0     0.000000\n",
      "8858       0       1     0.666667\n",
      "9014       0       0     0.000000\n",
      "1044       0       0     0.200000\n",
      "10272      0       0     0.000000\n",
      "3412       0       0     0.000000\n",
      "7919       0       0     0.028986\n",
      "9309       0       0     0.000000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " y_pred     0     1    All\n",
      "y_act                    \n",
      "0       8373   950   9323\n",
      "1       1560  1446   3006\n",
      "All     9933  2396  12329\n",
      "\n",
      "\n",
      "acuracy: 0.7964149566063752\n",
      "f1_score: [0.86965102 0.53535728]\n",
      "\n",
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      9323\n",
      "           1       0.60      0.48      0.54      3006\n",
      "\n",
      "    accuracy                           0.80     12329\n",
      "   macro avg       0.72      0.69      0.70     12329\n",
      "weighted avg       0.78      0.80      0.79     12329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a reusable function\n",
    "def evaluate_model(model, X_test, features_to_model):\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test[features_to_model])\n",
    "    y_pred_prob = model.predict_proba(X_test[features_to_model])[:,1]\n",
    "    print(y_pred_prob[:5])\n",
    "\n",
    "    test_result = pd.DataFrame(data={'y_act':y_test.values, 'y_pred':y_pred, 'y_pred_prob':y_pred_prob})\n",
    "    print(test_result.sample(10))\n",
    "    print('\\n')\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    cfm = pd.crosstab(test_result['y_act'], test_result['y_pred'], margins=True)\n",
    "    print(\"Confusion Matrix:\\n\", cfm)\n",
    "    print('\\n')\n",
    "\n",
    "    # Model evaluation\n",
    "    # Use Scikit-Learn function (lgr = Logistic Regression)\n",
    "    acuracy = metrics.accuracy_score(test_result['y_act'], test_result['y_pred']) \n",
    "    print(\"acuracy:\", acuracy)\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "    f1_score = metrics.f1_score(test_result['y_act'], test_result['y_pred'], average=None)  #weighted accounts for label imbalance.\n",
    "    print(\"f1_score:\",f1_score)\n",
    "    print('\\n')\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"classification_report:\\n\",classification_report(test_result['y_act'], test_result['y_pred']))\n",
    "\n",
    "evaluate_model(model, X_test, features_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Seraching for Optimum Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Parameters: {'C': 10}\n",
      "Best model score: 0.5601132349519123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\python-3.9.4.amd64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Python\\python-3.9.4.amd64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Python\\python-3.9.4.amd64\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=-1)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Python\\python-3.9.4.amd64\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.55987043 0.55987043 0.55987043 0.55987043 0.56011323]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define Hyperparameter Grid\n",
    "param_grid = {'C': [-1, 0.5, 1, 2, 5, 10]}\n",
    "  \n",
    "# Create model object\n",
    "model = LogisticRegression()\n",
    "  \n",
    "# Create GridSearchCV object\n",
    "model_cv = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "  \n",
    "model_cv.fit(X_train[features_to_model], y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Model Parameters: {}\".format(model_cv.best_params_))\n",
    "print(\"Best model score: {}\".format(model_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_profile:\n",
      "           feature  coefficients\n",
      "0             age      0.413143\n",
      "1  hours_per_week      0.414494\n",
      "2   education_num      0.970269\n",
      "3  marital_status      1.159556\n",
      "intercept: -1.884691330044252\n",
      "\n",
      "\n",
      "Model Parameters:\n",
      " C                        10\n",
      "class_weight           None\n",
      "dual                  False\n",
      "fit_intercept          True\n",
      "intercept_scaling         1\n",
      "l1_ratio               None\n",
      "max_iter                100\n",
      "multi_class            auto\n",
      "n_jobs                 None\n",
      "penalty                  l2\n",
      "random_state           None\n",
      "solver                lbfgs\n",
      "tol                  0.0001\n",
      "verbose                   0\n",
      "warm_start            False\n",
      "dtype: object\n",
      "[0.36441803 0.05192725 0.13732913 0.22632999 0.62849444]\n",
      "       y_act  y_pred  y_pred_prob\n",
      "9845       0       0     0.011892\n",
      "10674      1       1     0.679915\n",
      "5850       0       0     0.212903\n",
      "2729       0       0     0.145997\n",
      "7184       0       0     0.025069\n",
      "9002       1       1     0.770055\n",
      "3884       0       0     0.077954\n",
      "6082       1       0     0.367053\n",
      "6665       0       1     0.846538\n",
      "8598       0       0     0.205124\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " y_pred      0     1    All\n",
      "y_act                     \n",
      "0        8619   704   9323\n",
      "1        1540  1466   3006\n",
      "All     10159  2170  12329\n",
      "\n",
      "\n",
      "acuracy: 0.817990104631357\n",
      "f1_score: [0.88481675 0.56646059]\n",
      "\n",
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      9323\n",
      "           1       0.68      0.49      0.57      3006\n",
      "\n",
      "    accuracy                           0.82     12329\n",
      "   macro avg       0.76      0.71      0.73     12329\n",
      "weighted avg       0.81      0.82      0.81     12329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model_cv.best_estimator_\n",
    "\n",
    "# Feature importance/Coefficients\n",
    "coefficients = model.coef_[0]\n",
    "intercept = model.intercept_[0]\n",
    "feature_profile = pd.DataFrame({\"feature\":features_to_model, \"coefficients\":coefficients})\n",
    "print(\"feature_profile:\\n\", feature_profile)\n",
    "print(\"intercept:\", intercept)\n",
    "print('\\n')\n",
    "print(\"Model Parameters:\\n\", pd.Series(model.get_params()))\n",
    "\n",
    "# Evaluate Model\n",
    "evaluate_model(model, X_test, features_to_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Parameters: {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
      "Best model score: 0.598803082673162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define Hyperparameter Grid\n",
    "param_grid = {\"max_depth\": [5, 10],\n",
    "              \"min_samples_leaf\": [2, 10, 100],\n",
    "              \"min_samples_split\": [2, 10, 100]\n",
    "             }\n",
    "  \n",
    "# Create model object\n",
    "model = DecisionTreeClassifier()\n",
    " \n",
    "# Create GridSearchCV object\n",
    "model_cv = GridSearchCV(model, param_grid, cv=3, scoring='f1')\n",
    "  \n",
    "model_cv.fit(X_train[features_to_model], y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Model Parameters: {}\".format(model_cv.best_params_))\n",
    "print(\"Best model score: {}\".format(model_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_profile:\n",
      "           feature  importance\n",
      "0             age    0.102202\n",
      "1  hours_per_week    0.077442\n",
      "2   education_num    0.325678\n",
      "3  marital_status    0.494677\n",
      "\n",
      "\n",
      "Model Parameters:\n",
      " ccp_alpha                    0.0\n",
      "class_weight                None\n",
      "criterion                   gini\n",
      "max_depth                     10\n",
      "max_features                None\n",
      "max_leaf_nodes              None\n",
      "min_impurity_decrease        0.0\n",
      "min_samples_leaf              10\n",
      "min_samples_split            100\n",
      "min_weight_fraction_leaf     0.0\n",
      "random_state                None\n",
      "splitter                    best\n",
      "dtype: object\n",
      "[0.38504937 0.         0.08333333 0.02247191 0.79273504]\n",
      "       y_act  y_pred  y_pred_prob\n",
      "5699       1       0     0.406103\n",
      "152        0       0     0.000000\n",
      "4625       1       0     0.333333\n",
      "4440       1       0     0.385049\n",
      "5905       1       1     0.792735\n",
      "11186      1       1     0.521073\n",
      "2073       0       0     0.000000\n",
      "6020       1       0     0.469136\n",
      "11211      0       0     0.000000\n",
      "10890      1       1     0.569767\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " y_pred     0     1    All\n",
      "y_act                    \n",
      "0       8553   770   9323\n",
      "1       1411  1595   3006\n",
      "All     9964  2365  12329\n",
      "\n",
      "\n",
      "acuracy: 0.823100008110958\n",
      "f1_score: [0.88691865 0.59393037]\n",
      "\n",
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      9323\n",
      "           1       0.67      0.53      0.59      3006\n",
      "\n",
      "    accuracy                           0.82     12329\n",
      "   macro avg       0.77      0.72      0.74     12329\n",
      "weighted avg       0.81      0.82      0.82     12329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model_cv.best_estimator_\n",
    "\n",
    "# Feature importance/Coefficients\n",
    "importance = model.feature_importances_\n",
    "feature_profile = pd.DataFrame({\"feature\":features_to_model, \"importance\":importance})\n",
    "print(\"feature_profile:\\n\", feature_profile)\n",
    "print('\\n')\n",
    "print(\"Model Parameters:\\n\", pd.Series(model.get_params()))\n",
    "\n",
    "# Evaluate Model\n",
    "evaluate_model(model, X_test, features_to_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Parameters: {'min_samples_split': 20, 'min_samples_leaf': 10, 'max_depth': 3}\n",
      "Best model score: 0.7059251771725805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "    \n",
    "# Define Hyperparameter Grid\n",
    "param_grid = {\"max_depth\": [3, 10, 100],\n",
    "              \"min_samples_leaf\": [5, 10, 50, 100, 200],\n",
    "              \"min_samples_split\": [5, 10, 20, 100]\n",
    "             }\n",
    "  \n",
    "# Create model object\n",
    "model = DecisionTreeClassifier()\n",
    "  \n",
    "# Create RandomizedSearchCV object\n",
    "model_cv = RandomizedSearchCV(model, param_grid, cv=5, scoring='precision')\n",
    "  \n",
    "model_cv.fit(X_train[features_to_model], y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Model Parameters: {}\".format(model_cv.best_params_))\n",
    "print(\"Best model score: {}\".format(model_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_profile:\n",
      "           feature  importance\n",
      "0             age    0.000000\n",
      "1  hours_per_week    0.041041\n",
      "2   education_num    0.348718\n",
      "3  marital_status    0.610240\n",
      "\n",
      "\n",
      "Model Parameters:\n",
      " ccp_alpha                    0.0\n",
      "class_weight                None\n",
      "criterion                   gini\n",
      "max_depth                      3\n",
      "max_features                None\n",
      "max_leaf_nodes              None\n",
      "min_impurity_decrease        0.0\n",
      "min_samples_leaf              10\n",
      "min_samples_split             20\n",
      "min_weight_fraction_leaf     0.0\n",
      "random_state                None\n",
      "splitter                    best\n",
      "dtype: object\n",
      "[0.35927236 0.02719503 0.11867583 0.35927236 0.72826981]\n",
      "       y_act  y_pred  y_pred_prob\n",
      "10754      1       1     0.728270\n",
      "7095       1       0     0.118676\n",
      "2164       0       0     0.027195\n",
      "3780       1       1     0.728270\n",
      "3378       0       0     0.027195\n",
      "2817       0       0     0.359272\n",
      "11881      0       0     0.359272\n",
      "3710       0       0     0.359272\n",
      "4736       0       0     0.126486\n",
      "5772       1       0     0.359272\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " y_pred      0     1    All\n",
      "y_act                     \n",
      "0        8913   410   9323\n",
      "1        1832  1174   3006\n",
      "All     10745  1584  12329\n",
      "\n",
      "\n",
      "acuracy: 0.8181523237894396\n",
      "f1_score: [0.88827985 0.51154684]\n",
      "\n",
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      9323\n",
      "           1       0.74      0.39      0.51      3006\n",
      "\n",
      "    accuracy                           0.82     12329\n",
      "   macro avg       0.79      0.67      0.70     12329\n",
      "weighted avg       0.81      0.82      0.80     12329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model_cv.best_estimator_\n",
    "\n",
    "# Feature importance/Coefficients\n",
    "importance = model.feature_importances_\n",
    "feature_profile = pd.DataFrame({\"feature\":features_to_model, \"importance\":importance})\n",
    "print(\"feature_profile:\\n\", feature_profile)\n",
    "print('\\n')\n",
    "print(\"Model Parameters:\\n\", pd.Series(model.get_params()))\n",
    "\n",
    "# Evaluate Model\n",
    "evaluate_model(model, X_test, features_to_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Parameters: {'min_samples_split': 20, 'min_samples_leaf': 10, 'max_depth': 100}\n",
      "Best model score: 0.5820416079423019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "    \n",
    "# Define Hyperparameter Grid\n",
    "param_grid = {\"max_depth\": [3, 10, 100],\n",
    "              \"min_samples_leaf\": [5, 10, 50, 100, 200],\n",
    "              \"min_samples_split\": [5, 10, 20, 100]\n",
    "             }\n",
    "  \n",
    "# Create model object\n",
    "model = RandomForestClassifier()\n",
    "  \n",
    "# Create RandomizedSearchCV object\n",
    "model_cv = RandomizedSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "  \n",
    "model_cv.fit(X_train[features_to_model], y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Model Parameters: {}\".format(model_cv.best_params_))\n",
    "print(\"Best model score: {}\".format(model_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_profile:\n",
      "           feature  importance\n",
      "0             age    0.191971\n",
      "1  hours_per_week    0.113005\n",
      "2   education_num    0.296556\n",
      "3  marital_status    0.398468\n",
      "\n",
      "\n",
      "Model Parameters:\n",
      " bootstrap                    True\n",
      "ccp_alpha                     0.0\n",
      "class_weight                 None\n",
      "criterion                    gini\n",
      "max_depth                     100\n",
      "max_features                 auto\n",
      "max_leaf_nodes               None\n",
      "max_samples                  None\n",
      "min_impurity_decrease         0.0\n",
      "min_samples_leaf               10\n",
      "min_samples_split              20\n",
      "min_weight_fraction_leaf      0.0\n",
      "n_estimators                  100\n",
      "n_jobs                       None\n",
      "oob_score                   False\n",
      "random_state                 None\n",
      "verbose                         0\n",
      "warm_start                  False\n",
      "dtype: object\n",
      "[0.31810977 0.02420742 0.14910756 0.02311026 0.66006083]\n",
      "       y_act  y_pred  y_pred_prob\n",
      "9452       0       0     0.017286\n",
      "7006       0       0     0.019903\n",
      "12029      0       0     0.003496\n",
      "6657       0       0     0.071949\n",
      "8023       1       0     0.377788\n",
      "1225       0       0     0.052435\n",
      "5977       0       1     0.597890\n",
      "7590       0       0     0.100707\n",
      "7957       0       0     0.197570\n",
      "5641       1       0     0.410999\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " y_pred      0     1    All\n",
      "y_act                     \n",
      "0        8582   741   9323\n",
      "1        1446  1560   3006\n",
      "All     10028  2301  12329\n",
      "\n",
      "\n",
      "acuracy: 0.8226133506367101\n",
      "f1_score: [0.88698258 0.58790277]\n",
      "\n",
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      9323\n",
      "           1       0.68      0.52      0.59      3006\n",
      "\n",
      "    accuracy                           0.82     12329\n",
      "   macro avg       0.77      0.72      0.74     12329\n",
      "weighted avg       0.81      0.82      0.81     12329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model_cv.best_estimator_\n",
    "\n",
    "# Feature importance/Coefficients\n",
    "importance = model.feature_importances_\n",
    "feature_profile = pd.DataFrame({\"feature\":features_to_model, \"importance\":importance})\n",
    "print(\"feature_profile:\\n\", feature_profile)\n",
    "print('\\n')\n",
    "print(\"Model Parameters:\\n\", pd.Series(model.get_params()))\n",
    "\n",
    "# Evaluate Model\n",
    "evaluate_model(model, X_test, features_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Last update 2022-03-21 by Sumudu Tennakoon\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a5054f080f6f89f8108090c183ad9c7964b362bb8e166d0af3e56ae03939387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
